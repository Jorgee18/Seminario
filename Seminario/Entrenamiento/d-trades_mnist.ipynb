{"cells":[{"cell_type":"code","execution_count":1,"id":"aee93e0f-76fd-4c6c-becf-ae3ab9d64897","metadata":{"scrolled":true,"id":"aee93e0f-76fd-4c6c-becf-ae3ab9d64897","executionInfo":{"status":"ok","timestamp":1762637226650,"user_tz":180,"elapsed":9454,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["from __future__ import print_function\n","import os\n","import argparse\n","import torch, gc\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import time\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","# from autoattack import AutoAttack\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable"]},{"cell_type":"code","source":["%pip install import-ipynb"],"metadata":{"id":"IYap0KV-6FfK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762637234638,"user_tz":180,"elapsed":5226,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}},"outputId":"20fb2b13-52f0-4d63-e4d2-d5df4ada75c0"},"id":"IYap0KV-6FfK","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting import-ipynb\n","  Downloading import_ipynb-0.2-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.12/dist-packages (from import-ipynb) (7.34.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from import-ipynb) (5.10.4)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (75.2.0)\n","Collecting jedi>=0.16 (from IPython->import-ipynb)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (3.0.52)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (0.2.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from IPython->import-ipynb) (4.9.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->import-ipynb) (2.21.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->import-ipynb) (4.25.1)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->import-ipynb) (5.9.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.5)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.28.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.5.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.14)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->import-ipynb) (4.15.0)\n","Downloading import_ipynb-0.2-py3-none-any.whl (4.0 kB)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.2 jedi-0.19.2\n"]}]},{"cell_type":"code","source":["import import_ipynb\n","\n","from vgg import *\n","from d_trades import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPmcp6CJSQm3","executionInfo":{"status":"ok","timestamp":1762637252374,"user_tz":180,"elapsed":16892,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}},"outputId":"9485b136-dcf0-4b65-ecad-1934aa90fcca"},"id":"YPmcp6CJSQm3","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook vgg.ipynb to script\n","[NbConvertApp] Writing 2345 bytes to vgg.py\n","[NbConvertApp] WARNING | pattern 'Dtrades.ipynb' matched no files\n","This application is used to convert notebook files (*.ipynb)\n","        to various other formats.\n","\n","        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n","\n","Options\n","=======\n","The options below are convenience aliases to configurable class-options,\n","as listed in the \"Equivalent to\" description-line of the aliases.\n","To see all configurable class-options for some <cmd>, use:\n","    <cmd> --help-all\n","\n","--debug\n","    set log level to logging.DEBUG (maximize logging output)\n","    Equivalent to: [--Application.log_level=10]\n","--show-config\n","    Show the application's configuration (human-readable format)\n","    Equivalent to: [--Application.show_config=True]\n","--show-config-json\n","    Show the application's configuration (json format)\n","    Equivalent to: [--Application.show_config_json=True]\n","--generate-config\n","    generate default config file\n","    Equivalent to: [--JupyterApp.generate_config=True]\n","-y\n","    Answer yes to any questions instead of prompting.\n","    Equivalent to: [--JupyterApp.answer_yes=True]\n","--execute\n","    Execute the notebook prior to export.\n","    Equivalent to: [--ExecutePreprocessor.enabled=True]\n","--allow-errors\n","    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n","    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n","--stdin\n","    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n","    Equivalent to: [--NbConvertApp.from_stdin=True]\n","--stdout\n","    Write notebook output to stdout instead of files.\n","    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n","--inplace\n","    Run nbconvert in place, overwriting the existing notebook (only\n","            relevant when converting to notebook format)\n","    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n","--clear-output\n","    Clear output of current file and save in place,\n","            overwriting the existing notebook.\n","    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n","--coalesce-streams\n","    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n","    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n","--no-prompt\n","    Exclude input and output prompts from converted document.\n","    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n","--no-input\n","    Exclude input cells and output prompts from converted document.\n","            This mode is ideal for generating code-free reports.\n","    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n","--allow-chromium-download\n","    Whether to allow downloading chromium if no suitable version is found on the system.\n","    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n","--disable-chromium-sandbox\n","    Disable chromium security sandbox when converting to PDF..\n","    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n","--show-input\n","    Shows code input. This flag is only useful for dejavu users.\n","    Equivalent to: [--TemplateExporter.exclude_input=False]\n","--embed-images\n","    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n","    Equivalent to: [--HTMLExporter.embed_images=True]\n","--sanitize-html\n","    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n","    Equivalent to: [--HTMLExporter.sanitize_html=True]\n","--log-level=<Enum>\n","    Set the log level by value or name.\n","    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n","    Default: 30\n","    Equivalent to: [--Application.log_level]\n","--config=<Unicode>\n","    Full path of a config file.\n","    Default: ''\n","    Equivalent to: [--JupyterApp.config_file]\n","--to=<Unicode>\n","    The export format to be used, either one of the built-in formats\n","            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n","            or a dotted object name that represents the import path for an\n","            ``Exporter`` class\n","    Default: ''\n","    Equivalent to: [--NbConvertApp.export_format]\n","--template=<Unicode>\n","    Name of the template to use\n","    Default: ''\n","    Equivalent to: [--TemplateExporter.template_name]\n","--template-file=<Unicode>\n","    Name of the template file to use\n","    Default: None\n","    Equivalent to: [--TemplateExporter.template_file]\n","--theme=<Unicode>\n","    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n","    as prebuilt extension for the lab template)\n","    Default: 'light'\n","    Equivalent to: [--HTMLExporter.theme]\n","--sanitize_html=<Bool>\n","    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n","    should be set to True by nbviewer or similar tools.\n","    Default: False\n","    Equivalent to: [--HTMLExporter.sanitize_html]\n","--writer=<DottedObjectName>\n","    Writer class used to write the\n","                                        results of the conversion\n","    Default: 'FilesWriter'\n","    Equivalent to: [--NbConvertApp.writer_class]\n","--post=<DottedOrNone>\n","    PostProcessor class used to write the\n","                                        results of the conversion\n","    Default: ''\n","    Equivalent to: [--NbConvertApp.postprocessor_class]\n","--output=<Unicode>\n","    Overwrite base name use for output files.\n","                Supports pattern replacements '{notebook_name}'.\n","    Default: '{notebook_name}'\n","    Equivalent to: [--NbConvertApp.output_base]\n","--output-dir=<Unicode>\n","    Directory to write output(s) to. Defaults\n","                                  to output to the directory of each notebook. To recover\n","                                  previous default behaviour (outputting to the current\n","                                  working directory) use . as the flag value.\n","    Default: ''\n","    Equivalent to: [--FilesWriter.build_directory]\n","--reveal-prefix=<Unicode>\n","    The URL prefix for reveal.js (version 3.x).\n","            This defaults to the reveal CDN, but can be any url pointing to a copy\n","            of reveal.js.\n","            For speaker notes to work, this must be a relative path to a local\n","            copy of reveal.js: e.g., \"reveal.js\".\n","            If a relative path is given, it must be a subdirectory of the\n","            current directory (from which the server is run).\n","            See the usage documentation\n","            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n","            for more details.\n","    Default: ''\n","    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n","--nbformat=<Enum>\n","    The nbformat version to write.\n","            Use this to downgrade notebooks.\n","    Choices: any of [1, 2, 3, 4]\n","    Default: 4\n","    Equivalent to: [--NotebookExporter.nbformat_version]\n","\n","Examples\n","--------\n","\n","    The simplest way to use nbconvert is\n","\n","            > jupyter nbconvert mynotebook.ipynb --to html\n","\n","            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n","\n","            > jupyter nbconvert --to latex mynotebook.ipynb\n","\n","            Both HTML and LaTeX support multiple output templates. LaTeX includes\n","            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n","            'classic'. You can specify the flavor of the format used.\n","\n","            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n","\n","            You can also pipe the output to stdout, rather than a file\n","\n","            > jupyter nbconvert mynotebook.ipynb --stdout\n","\n","            PDF is generated via latex\n","\n","            > jupyter nbconvert mynotebook.ipynb --to pdf\n","\n","            You can get (and serve) a Reveal.js-powered slideshow\n","\n","            > jupyter nbconvert myslides.ipynb --to slides --post serve\n","\n","            Multiple notebooks can be given at the command line in a couple of\n","            different ways:\n","\n","            > jupyter nbconvert notebook*.ipynb\n","            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n","\n","            or you can specify the notebooks list in a config file, containing::\n","\n","                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n","\n","            > jupyter nbconvert --config mycfg.py\n","\n","To see all available configurables, use `--help-all`.\n","\n"]}]},{"cell_type":"code","execution_count":4,"id":"72ab71e8-4641-4b73-b1d1-0ffdb35e6602","metadata":{"id":"72ab71e8-4641-4b73-b1d1-0ffdb35e6602","executionInfo":{"status":"ok","timestamp":1762637252409,"user_tz":180,"elapsed":32,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["parser = argparse.ArgumentParser(description='PyTorch MNIST TRADES Adversarial Training')\n","parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n","                    help='input batch size for training (default: 128)')\n","parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n","                    help='input batch size for testing (default: 128)')\n","parser.add_argument('--epochs', type=int, default=50, metavar='N',\n","                    help='number of epochs to train')\n","parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n","                    help='learning rate')\n","parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n","                    help='SGD momentum')\n","parser.add_argument('--no-cuda', action='store_true', default=False,\n","                    help='disables CUDA training')\n","parser.add_argument('--epsilon', default=0.3,\n","                    help='perturbation')\n","parser.add_argument('--num-steps', default=20,\n","                    help='perturb number of steps')\n","parser.add_argument('--step-size', default=0.01,\n","                    help='perturb step size')\n","parser.add_argument('--alpha', default=1.0,\n","                    help='regularization, i.e., 1/lambda in TRADES')\n","parser.add_argument('--beta', default=1.0,\n","                    help='regularization, i.e., 1/lambda in TRADES')\n","parser.add_argument('--seed', type=int, default=1, metavar='S',\n","                    help='random seed (default: 1)')\n","parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n","                    help='how many batches to wait before logging training status')\n","parser.add_argument('--model-dir', default='./model-trades-mnist-resnet18',\n","                    help='directory of model for saving checkpoint')\n","parser.add_argument('--save-freq', '-s', default=3, type=int, metavar='N',\n","                    help='save frequency')\n","args, unknown = parser.parse_known_args()\n"]},{"cell_type":"code","execution_count":5,"id":"1adf9d33-39ed-488f-8b30-33b8ad56ce1c","metadata":{"id":"1adf9d33-39ed-488f-8b30-33b8ad56ce1c","executionInfo":{"status":"ok","timestamp":1762637252436,"user_tz":180,"elapsed":24,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["model_dir = args.model_dir\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)\n","use_cuda = not args.no_cuda and torch.cuda.is_available()\n","torch.manual_seed(args.seed)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"]},{"cell_type":"code","execution_count":6,"id":"806ac204-6b7c-433a-a0c6-17b8cc8b3902","metadata":{"id":"806ac204-6b7c-433a-a0c6-17b8cc8b3902","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762637255578,"user_tz":180,"elapsed":3139,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}},"outputId":"66cdd9b8-97ae-4691-b11e-d418c1563dee"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 20.2MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 476kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.46MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 9.09MB/s]\n"]}],"source":["# setup data loader\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=transforms.ToTensor()),\n","    batch_size=args.batch_size, shuffle=True, **kwargs)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False,\n","                   transform=transforms.ToTensor()),\n","                   batch_size=args.test_batch_size, shuffle=False, **kwargs)"]},{"cell_type":"code","execution_count":null,"id":"a55704ac-d400-41f0-b2ac-490fdad956a2","metadata":{"id":"a55704ac-d400-41f0-b2ac-490fdad956a2"},"outputs":[],"source":["#transform = transforms.ToTensor()\n","#train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)"]},{"cell_type":"code","execution_count":null,"id":"7809a1d9-dc62-4440-83fc-d88f946fc6d2","metadata":{"id":"7809a1d9-dc62-4440-83fc-d88f946fc6d2"},"outputs":[],"source":["#k_folds = 5\n","#kfold = KFold(n_splits=k_folds, shuffle=True)"]},{"cell_type":"code","execution_count":7,"id":"628ae062-7c37-4daa-973b-4ac7bef3b321","metadata":{"id":"628ae062-7c37-4daa-973b-4ac7bef3b321","executionInfo":{"status":"ok","timestamp":1762637255585,"user_tz":180,"elapsed":3,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["lambda_min = []\n","lambda_max = []\n","lambda_mean = []\n","current_epoch = []\n","def train(args, model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # calculate robust loss\n","        # MODIFIED: d_trades_loss now returns both loss and lambda_value_calculated\n","        loss, lambda_value = d_trades_loss(model=model,\n","                                                 x_natural=data,\n","                                                 y=target,\n","                                                 optimizer=optimizer,\n","                                                 step_size=args.step_size,\n","                                                 epsilon=args.epsilon,\n","                                                 perturb_steps=args.num_steps,\n","                                                 alpha=args.alpha,\n","                                                 beta=args.beta)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print progress\n","        if batch_idx % args.log_interval == 0:\n","            # MODIFIED: Use lambda for logging\n","            lambda_min.append(lambda_value.min().item())\n","            lambda_max.append(lambda_value.max().item())\n","            lambda_mean.append(lambda_value.mean().item())\n","            current_epoch.append(epoch + batch_idx)\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n"]},{"cell_type":"code","execution_count":8,"id":"64108166-f237-4915-b56f-4a2fcb9f54ef","metadata":{"id":"64108166-f237-4915-b56f-4a2fcb9f54ef","executionInfo":{"status":"ok","timestamp":1762637255591,"user_tz":180,"elapsed":3,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["def _pgd_whitebox(model,\n","                  X,\n","                  y,\n","                  epsilon=args.epsilon,\n","                  num_steps=20,\n","                  step_size=0.003):\n","    out = model(X)\n","    err = (out.data.max(1)[1] != y.data).float().sum()\n","    X_pgd = Variable(X.data, requires_grad=True)\n","\n","    random_noise = torch.FloatTensor(*X_pgd.shape).uniform_(-epsilon, epsilon).to(device)\n","    X_pgd = Variable(X_pgd.data + random_noise, requires_grad=True)\n","\n","    for _ in range(num_steps):\n","        opt = optim.SGD([X_pgd], lr=1e-3)\n","        opt.zero_grad()\n","\n","        with torch.enable_grad():\n","            loss = nn.CrossEntropyLoss()(model(X_pgd), y)\n","        loss.backward()\n","        eta = step_size * X_pgd.grad.data.sign()\n","        X_pgd = Variable(X_pgd.data + eta, requires_grad=True)\n","        eta = torch.clamp(X_pgd.data - X.data, -epsilon, epsilon)\n","        X_pgd = Variable(X.data + eta, requires_grad=True)\n","        X_pgd = Variable(torch.clamp(X_pgd, 0, 1.0), requires_grad=True)\n","    err_pgd = (model(X_pgd).data.max(1)[1] != y.data).float().sum()\n","    return err, err_pgd"]},{"cell_type":"code","execution_count":9,"id":"f6021d23-b8fa-464d-95d7-1d19d750c17b","metadata":{"id":"f6021d23-b8fa-464d-95d7-1d19d750c17b","executionInfo":{"status":"ok","timestamp":1762637255632,"user_tz":180,"elapsed":36,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["def eval_adv_test_whitebox(model, device, test_loader):\n","\n","    model.eval()\n","    robust_err_total = 0\n","    natural_err_total = 0\n","\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        # pgd attack\n","        X, y = Variable(data, requires_grad=True), Variable(target)\n","        err_natural, err_robust = _pgd_whitebox(model, X, y)\n","        robust_err_total += err_robust\n","        natural_err_total += err_natural\n","\n","    natural_acc = 1 - natural_err_total / len(test_loader.dataset)\n","    robust_acc = 1- robust_err_total / len(test_loader.dataset)\n","    robust_drop = natural_acc - robust_acc\n","    attack_success_rate = 1 - robust_acc\n","\n","\n","    #print('natural_acc: ', 1 - natural_err_total / len(test_loader.dataset))\n","    #print('robust_acc: ', 1- robust_err_total / len(test_loader.dataset))\n","    print(f'PGD natural_acc: {natural_acc:.4f}, robust_acc: {robust_acc:.4f}, robust_drop: {robust_drop:4f}, attack_success_rate: {attack_success_rate:4f}')\n","    return natural_acc, robust_acc, robust_drop, attack_success_rate"]},{"cell_type":"code","execution_count":10,"id":"d8fd9e6b-9d57-4707-ac90-614f929f420b","metadata":{"id":"d8fd9e6b-9d57-4707-ac90-614f929f420b","executionInfo":{"status":"ok","timestamp":1762637255637,"user_tz":180,"elapsed":3,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"decrease the learning rate\"\"\"\n","    lr = args.lr\n","    if epoch >= 55:\n","        lr = args.lr * 0.1\n","    if epoch >= 75:\n","        lr = args.lr * 0.01\n","    if epoch >= 90:\n","        lr = args.lr * 0.001\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"]},{"cell_type":"code","execution_count":11,"id":"4b5396aa-be50-4358-9a84-ba3de1c1995f","metadata":{"id":"4b5396aa-be50-4358-9a84-ba3de1c1995f","executionInfo":{"status":"ok","timestamp":1762637255745,"user_tz":180,"elapsed":7,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":12,"id":"bdce7e24-6ec3-47b7-959a-f55c91a85872","metadata":{"scrolled":true,"id":"bdce7e24-6ec3-47b7-959a-f55c91a85872","outputId":"f0db35c7-7823-4ee0-cf7c-af0d36ebba73","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1762644095299,"user_tz":180,"elapsed":6839522,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.410892\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.206947\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.216552\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.138155\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.142490\n","================================================================\n","PGD natural_acc: 0.9875, robust_acc: 0.9597, robust_drop: 0.027800, attack_success_rate: 0.040300\n","using time: 1115.489494562149\n","================================================================\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.155536\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.085409\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.092830\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.203812\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.134827\n","================================================================\n","PGD natural_acc: 0.9901, robust_acc: 0.9689, robust_drop: 0.021200, attack_success_rate: 0.031100\n","using time: 1116.6608264446259\n","================================================================\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.139407\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.056019\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.069129\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.062696\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.107942\n","================================================================\n","PGD natural_acc: 0.9930, robust_acc: 0.9690, robust_drop: 0.024000, attack_success_rate: 0.031000\n","using time: 1119.6472692489624\n","================================================================\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.047045\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.101582\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.070637\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.063949\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.053266\n","================================================================\n","PGD natural_acc: 0.9935, robust_acc: 0.9685, robust_drop: 0.025000, attack_success_rate: 0.031500\n","using time: 1118.159054517746\n","================================================================\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.077897\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.050609\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.052070\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.066696\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.047477\n","================================================================\n","PGD natural_acc: 0.9926, robust_acc: 0.9730, robust_drop: 0.019600, attack_success_rate: 0.027000\n","using time: 1116.8133642673492\n","================================================================\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.099818\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.089606\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.051595\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.051773\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.045304\n","================================================================\n","PGD natural_acc: 0.9931, robust_acc: 0.9734, robust_drop: 0.019700, attack_success_rate: 0.026600\n","using time: 1115.3598275184631\n","================================================================\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.020140\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-289441831.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-289441831.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3053250465.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# calculate robust loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# MODIFIED: d_trades_loss now returns both loss and lambda_value_calculated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         loss, lambda_value = d_trades_loss(model=model,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                                  \u001b[0mx_natural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                  \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36md_trades_loss\u001b[0;34m(model, x_natural, y, optimizer, step_size, epsilon, perturb_steps, distance, alpha, beta, normalize_terms, per_sample_sensitivity, EPS)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def main():\n","    #init model, Net() can be also used here for training\n","    # model = ResNet18()\n","    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","    model = vgg16(in_channels=1)\n","    model = model.to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n","\n","    history = {'natural_acc': [], 'robust_acc': [], 'robust_drop': [], 'attack_succes_rate': []}\n","    results = {}\n","\n","    for epoch in range(1, args.epochs + 1):\n","        # adjust learning rate for SGD\n","        adjust_learning_rate(optimizer, epoch)\n","\n","        start_time = time.time()\n","\n","        # adversarial training\n","        train(args, model, device, train_loader, optimizer, epoch)\n","\n","\n","        print('================================================================')\n","        #evaluation\n","        natural_acc, robust_acc, robust_drop, attack_succes_rate = eval_adv_test_whitebox(model, device, test_loader)\n","        print('using time:', time.time()-start_time)\n","        print('================================================================')\n","\n","        history['natural_acc'].append(natural_acc)\n","        history['robust_acc'].append(robust_acc)\n","        history['robust_drop'].append(robust_drop)\n","        history['attack_succes_rate'].append(attack_succes_rate)\n","\n","        results[f'history{epoch}'] = history\n","\n","        # save checkpoint\n","        if epoch % args.save_freq == 0:\n","            torch.save(model.state_dict(),\n","                       os.path.join(model_dir, 'model-nn-epoch{}.pt'.format(epoch)))\n","            torch.save(optimizer.state_dict(),\n","                       os.path.join(model_dir, 'opt-nn-checkpoint_epoch{}.tar'.format(epoch)))\n","\n","    print('================================================================')\n","    print(\"\\nResumen de Resultados por historial:\")\n","    for epochs, history in results.items():\n","        print(f\"{epochs}: Max Robust Acc: {max(history['robust_acc']):.4f}\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":13,"id":"c2113ad1-6efe-4961-ad04-70ee29729a0a","metadata":{"id":"c2113ad1-6efe-4961-ad04-70ee29729a0a","outputId":"16138310-fe44-4840-a3a6-8d081591664b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762645295762,"user_tz":180,"elapsed":220,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo cargado y listo para evaluación desde: ./model-trades-mnist-resnet18/model-nn-epoch5.pt\n"]}],"source":["# 1. Instancia el modelo con la arquitectura EXACTA que usaste (ej. ResNet18 o VGG)\n","# Si usaste VGG16 con 1 canal, asegúrate de que esté correctamente definida.\n","model = vgg16(in_channels=1).to(device)\n","\n","# 2. Define la ruta al archivo\n","# Debes reemplazar 'epoch_num' con el número de época que quieres cargar (ej., 1 o 50)\n","MODEL_PATH = os.path.join(model_dir, 'model-nn-epoch5.pt'.format(1))\n","\n","# 3. Carga los pesos en el modelo\n","# 'map_location' es útil si entrenaste en GPU y ahora cargas en CPU, o viceversa.\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n","\n","# 4. Pon el modelo en modo de evaluación si vas a probar ataques\n","model.eval()\n","\n","print(f\"Modelo cargado y listo para evaluación desde: {MODEL_PATH}\")"]},{"cell_type":"code","execution_count":14,"id":"8f1947e4-c67b-4ef8-a916-b6fbb974252d","metadata":{"id":"8f1947e4-c67b-4ef8-a916-b6fbb974252d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762645314564,"user_tz":180,"elapsed":68,"user":{"displayName":"ADEMIR DANTE MUÑOZ RODRIGUEZ","userId":"12418499374271777814"}},"outputId":"6aeb480b-3c6c-4d86-d036-4717931a1b7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Estado del optimizador cargado desde: ./model-trades-mnist-resnet18/opt-nn-checkpoint_epoch5.tar\n"]}],"source":["# 1. Asegúrate de que el modelo ya esté cargado (ver paso 1)\n","# y que el optimizador esté inicializado con los parámetros del modelo cargado.\n","optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n","\n","# 2. Define la ruta al archivo\n","# Reemplaza 'epoch_num' con el número de época\n","OPTIMIZER_PATH = os.path.join(model_dir, 'opt-nn-checkpoint_epoch5.tar'.format(1))\n","\n","# 3. Carga el estado en el optimizador\n","optimizer.load_state_dict(torch.load(OPTIMIZER_PATH, map_location=device))\n","\n","print(f\"Estado del optimizador cargado desde: {OPTIMIZER_PATH}\")"]},{"cell_type":"code","execution_count":null,"id":"a8e7c3cd-700c-4e60-88c9-2fba7da19eaa","metadata":{"scrolled":true,"id":"a8e7c3cd-700c-4e60-88c9-2fba7da19eaa"},"outputs":[],"source":["model = vgg16(in_channels=1)\n","model = model.to(device)\n","\n","checkpoint_path = \"model-trades-mnist-vgg16/model-nn-epoch1.pt\"\n","model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n","\n","optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n","optimizer.load_state_dict(torch.load(\"model-trades-mnist-vgg16/opt-nn-checkpoint_epoch1.tar\"))\n","\n","print(\"Modelo y optimizador cargados correctamente ✅\")"]},{"cell_type":"code","execution_count":null,"id":"90becbe7-9a9c-4788-8493-eb9de4e0332a","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"scrolled":true,"id":"90becbe7-9a9c-4788-8493-eb9de4e0332a","outputId":"72a6b77d-43d3-4713-d0a1-f0e6e3362ed2","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.472212\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.299362\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.195791\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.096577\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.111393\n","================================================================\n","PGD natural_acc: 0.9902, robust_acc: 0.9652, robust_drop: 0.025000, attack_success_rate: 0.034800\n","using time: 1113.5546910762787\n","================================================================\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.151081\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.257301\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.216073\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.051275\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.069454\n","================================================================\n","PGD natural_acc: 0.9909, robust_acc: 0.9691, robust_drop: 0.021800, attack_success_rate: 0.030900\n","using time: 1118.1482045650482\n","================================================================\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.067008\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.090818\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.086868\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.073226\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.073801\n","================================================================\n","PGD natural_acc: 0.9917, robust_acc: 0.9642, robust_drop: 0.027500, attack_success_rate: 0.035800\n","using time: 1119.8488037586212\n","================================================================\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.088309\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.084048\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.083635\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.073226\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.070073\n","================================================================\n","PGD natural_acc: 0.9923, robust_acc: 0.9456, robust_drop: 0.046700, attack_success_rate: 0.054400\n","using time: 1118.4280734062195\n","================================================================\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.054589\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.067152\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.080478\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.076321\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.079889\n","================================================================\n","PGD natural_acc: 0.9922, robust_acc: 0.9642, robust_drop: 0.028000, attack_success_rate: 0.035800\n","using time: 1116.6252443790436\n","================================================================\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.049713\n","Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.040334\n","Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.040993\n","Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.057136\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.037266\n","================================================================\n","PGD natural_acc: 0.9933, robust_acc: 0.9730, robust_drop: 0.020300, attack_success_rate: 0.027000\n","using time: 1117.8241181373596\n","================================================================\n","Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.033500\n"]}],"source":["def main():\n","    #init model, Net() can be also used here for training\n","    #model = ResNet18()\n","    #model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","    model = vgg16(in_channels=1)\n","    model = model.to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n","\n","    history = {'natural_acc': [], 'robust_acc': [], 'robust_drop': [], 'attack_succes_rate': []}\n","    results = {}\n","\n","    for epoch in range(5, args.epochs + 1):\n","        # adjust learning rate for SGD\n","        adjust_learning_rate(optimizer, epoch)\n","\n","        start_time = time.time()\n","\n","        # adversarial training\n","        train(args, model, device, train_loader, optimizer, epoch)\n","\n","\n","        print('================================================================')\n","        #evaluation\n","        natural_acc, robust_acc, robust_drop, attack_succes_rate = eval_adv_test_whitebox(model, device, test_loader)\n","        print('using time:', time.time()-start_time)\n","        print('================================================================')\n","\n","        history['natural_acc'].append(natural_acc)\n","        history['robust_acc'].append(robust_acc)\n","        history['robust_drop'].append(robust_drop)\n","        history['attack_succes_rate'].append(attack_succes_rate)\n","\n","        results[f'history{epoch}'] = history\n","\n","        # save checkpoint\n","        if epoch % args.save_freq == 0:\n","            torch.save(model.state_dict(),\n","                       os.path.join(model_dir, 'model-nn-epoch{}.pt'.format(epoch)))\n","            torch.save(optimizer.state_dict(),\n","                       os.path.join(model_dir, 'opt-nn-checkpoint_epoch{}.tar'.format(epoch)))\n","\n","    print('================================================================')\n","    print(\"\\nResumen de Resultados por historial:\")\n","    for epochs, history in results.items():\n","        print(f\"{epochs}: Max Robust Acc: {max(history['robust_acc']):.4f}\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"id":"14429ba4-4ba4-45f9-901d-c5e25fbc1bb1","metadata":{"id":"14429ba4-4ba4-45f9-901d-c5e25fbc1bb1"},"outputs":[],"source":["def eval_autoattack_direct(model, device, test_loader, eps=8/255, bs=128, version='standard'):\n","    \"\"\"\n","    Evalúa modelo con AutoAttack (modelo debe aceptar imágenes en [0,1] y devolver logits).\n","    Devuelve: natural_acc (float), robust_acc (float)\n","    \"\"\"\n","    model.to(device)\n","    model.eval()\n","\n","    # 1) Recolectar todo el test set en numpy (AutoAttack espera arrays numpy)\n","    xs = []\n","    ys = []\n","    for xb, yb in test_loader:\n","        xs.append(xb)        # ¡NO .cpu().numpy()!\n","        ys.append(yb)\n","    x_all_tensor = torch.cat(xs, dim=0)    # tensor en CPU\n","    y_all_tensor = torch.cat(ys, dim=0)\n","\n","    # 2) natural accuracy (compute with torch in device, batched to avoid overflow)\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for xb, yb in test_loader:\n","            xb = xb.to(device)\n","            yb = yb.to(device)\n","            logits = model(xb)\n","            pred = logits.argmax(dim=1)\n","            correct += (pred == yb).sum().item()\n","            total += yb.size(0)\n","    natural_acc = correct / total\n","\n","    # 3) AutoAttack (white-box)\n","    # AutoAttack expects the forward to receive inputs in [0,1] and return logits (numpy)\n","    adversary = AutoAttack(model, norm='Linf', eps=eps, version=version, verbose=False)\n","\n","    # run_standard_evaluation imprimirá por pantalla y retorna el robust accuracy (dependiendo de versión puede ser float o tuple)\n","    aa_out = adversary.run_standard_evaluation(x_all_tensor, y_all_tensor, bs=bs)\n","\n","    # aa_out suele devolver robust accuracy (float). Manejo defensivo:\n","    if isinstance(aa_out, tuple):\n","        robust_acc = aa_out[0]\n","    else:\n","        robust_acc = aa_out\n","\n","    print(f'AutoAttack (eps={eps}) -> natural_acc: {natural_acc:.4f}, robust_acc: {robust_acc:.4f}')\n","    return float(natural_acc), float(robust_acc)"]},{"cell_type":"code","source":["max_epoch = int(np.ceil(epoch_np.max()))\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(current_epoch, lambda_mean, label='Lambda Mean', color='royalblue', marker='o')\n","plt.plot(current_epoch, lambda_min,  label='Lambda Min',  color='seagreen', linestyle='--', marker='s')\n","plt.plot(current_epoch, lambda_max,  label='Lambda Max',  color='crimson', linestyle='--', marker='^')\n","\n","# Rango del eje X y ticks coherentes con tus datos\n","plt.xlim(1, max_epoch)\n","plt.xticks(np.arange(1, max_epoch + 1, 1))\n","\n","# Formato del gráfico\n","plt.title(\"Evolución del parámetro dinámico λ(x) durante el entrenamiento\")\n","plt.xlabel(\"Época (progreso del entrenamiento)\")\n","plt.ylabel(\"Valor de λ(x)\")\n","plt.grid(True, linestyle='--', alpha=0.4)\n","plt.legend()\n","plt.tight_layout()\n","\n","# Mostrar gráfico\n","plt.show()"],"metadata":{"id":"kIsu5zM_Mur3"},"id":"kIsu5zM_Mur3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"bca89631-54f8-4ac6-a69f-b24b6dcf4a3a","metadata":{"scrolled":true,"id":"bca89631-54f8-4ac6-a69f-b24b6dcf4a3a"},"outputs":[],"source":["\"\"\"\n","def main():\n","    results = {}\n","    best_val_acc = 0\n","    best_model_state = None\n","\n","    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n","        current_fold = fold + 1\n","        print(f'Fold {fold+1}')\n","\n","        train_subset = Subset(train_dataset, train_idx)\n","        val_subset = Subset(train_dataset, val_idx)\n","\n","        train_loader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=True)\n","        val_loader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False)\n","\n","        #model = ResNet18()\n","        #model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        model = vgg16(in_channels=1)\n","\n","        model = model.to(device)\n","        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n","        fold_history = {'natural_acc': [], 'robust_acc': [], 'robust_drop': [], 'attack_succes_rate': []}\n","\n","        for epoch in range(1, args.epochs + 1):\n","            # adjust learning rate for SGD\n","            adjust_learning_rate(optimizer, epoch)\n","\n","            start_time = time.time()\n","\n","            # adversarial training\n","            train(args, model, device, train_loader, optimizer, epoch)\n","\n","            print('================================================================')\n","            #evaluation\n","            nat_acc, robust_acc, robust_drop, attack_succes_rate = eval_adv_test_whitebox(model, device, val_loader)\n","            print('using time:', time.time()-start_time)\n","            print('================================================================')\n","\n","            #Guardado de fold\n","            fold_history['natural_acc'].append(nat_acc)\n","            fold_history['robust_acc'].append(robust_acc)\n","            fold_history['robust_drop'].append(nat_acc)\n","            fold_history['attack_succes_rate'].append(robust_acc)\n","\n","            if robust_acc > best_val_acc:\n","                best_val_acc = robust_acc\n","                best_model_state = model.state_dict()\n","                print(f\"Mejor modelo guardado en Fold {current_fold}, Epoch {epoch} con Robust Acc: {best_val_acc:.4f}\")\n","\n","        results[f'fold_{current_fold}'] = fold_history\n","\n","        torch.save(best_model_state, os.path.join(model_dir, 'model-nn-epoch{}.pt'.format(epoch)))\n","        torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res-checkpoint_epoch{}.tar'.format(epoch)))\n","        print(f\"Pesos del mejor modelo robusto guardados. Mejor Acc: {best_val_acc:.4f}\")\n","\n","\n","    #if best_model_state:\n","        #final_best_model = ResNet18()\n","        #final_best_model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","    #    final_best_model = vgg16(in_channels = 1)\n","\n","    #    final_best_model.load_state_dict(best_model_state)\n","    #    torch.save(final_best_model.state_dict(), os.path.join(model_dir, 'model-nn-epoch{}.pt'.format(epoch)))\n","    #    print(f\"Pesos del mejor modelo robusto guardados. Mejor Acc: {best_val_acc:.4f}\")\n","\n","    print(\"\\nResumen de Resultados por Fold:\")\n","    for fold_name, history in results.items():\n","        print(f\"{fold_name}: Max Robust Acc: {max(history['robust_acc']):.4f}\")\n","\n","        # save checkpoint\n","        #if epoch % args.save_freq == 0:\n","        #    torch.save(model.state_dict(),\n","        #               os.path.join(model_dir, 'model-nn-epoch{}.pt'.format(epoch)))\n","        #    torch.save(optimizer.state_dict(),\n","        #               os.path.join(model_dir, 'opt-nn-checkpoint_epoch{}.tar'.format(epoch)))\n","\n","if __name__ == '__main__':\n","    main()\n","\"\"\""]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}