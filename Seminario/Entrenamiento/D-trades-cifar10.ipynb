{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d356f7-d11a-4a0f-8a66-73cce020a9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch, gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import time\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from models.resnet import *\n",
    "from models.vgg import *\n",
    "from strategies.Dtrades import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3ec7d1-c94c-4e20-ab2e-7c78e0b5e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR D-TRADES Adversarial Training')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for testing (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=100, metavar='N', #76\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--weight-decay', '--wd', default=2e-4,\n",
    "                    type=float, metavar='W')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--epsilon', default=0.031,\n",
    "                    help='perturbation')\n",
    "parser.add_argument('--num-steps', default=10,\n",
    "                    help='perturb number of steps')\n",
    "parser.add_argument('--step-size', default=0.007,\n",
    "                    help='perturb step size')\n",
    "parser.add_argument('--alpha', default=1,\n",
    "                    help='regularization, i.e., 1/lambda in D-TRADES')\n",
    "parser.add_argument('--beta', default=1,\n",
    "                    help='regularization, i.e., 1/lambda in D-TRADES')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--model-dir', default='./testing',\n",
    "                    help='directory of model for saving checkpoint')\n",
    "parser.add_argument('--save-freq', '-s', default=1, type=int, metavar='N',\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--model', type=str, default='vgg', choices=['resnet', 'vgg'],\n",
    "                    help='Modelo a usar: resnet o vgg')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b50764a8-3f74-4718-9bca-92196119e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "model_dir = args.model_dir\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a9ae970-ce0a-4d9e-9d08-5a65baf5e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el cargador de datos\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538722bf-98b8-4528-84bf-19018023ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_min = []\n",
    "lambda_max = []\n",
    "lambda_mean = []\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate robust loss\n",
    "        loss, lambda_value = d_trades_loss(model=model,\n",
    "                           x_natural=data,\n",
    "                           y=target,\n",
    "                           optimizer=optimizer,\n",
    "                           step_size=args.step_size,\n",
    "                           epsilon=args.epsilon,\n",
    "                           perturb_steps=args.num_steps,\n",
    "                           alpha=args.alpha,\n",
    "                           beta=args.beta,\n",
    "                        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print progress\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            lambda_min.append(lambda_value.min().item())\n",
    "            lambda_max.append(lambda_value.max().item())\n",
    "            lambda_mean.append(lambda_value.mean().item())\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tLambda Mean: {:.2f} \\tLambda Min: {:.2f} \\tLambda Max: {:.2f}'.format(\n",
    "                                            epoch,\n",
    "                                            batch_idx * len(data),\n",
    "                                            len(train_loader.dataset),\n",
    "                                            100. * batch_idx / len(train_loader),\n",
    "                                            loss.item(),\n",
    "                                            lambda_value.mean().item(),\n",
    "                                            lambda_value.min().item(),\n",
    "                                            lambda_value.max().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1bbacde-84d7-4965-85d4-c55a0f15792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pgd_whitebox(model,\n",
    "                  X,\n",
    "                  y,\n",
    "                  epsilon=args.epsilon,\n",
    "                  num_steps=20,\n",
    "                  step_size=0.003):\n",
    "    out = model(X)\n",
    "    err = (out.data.max(1)[1] != y.data).float().sum()\n",
    "    X_pgd = Variable(X.data, requires_grad=True)\n",
    "\n",
    "    random_noise = torch.FloatTensor(*X_pgd.shape).uniform_(-epsilon, epsilon).to(device)\n",
    "    X_pgd = Variable(X_pgd.data + random_noise, requires_grad=True)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        opt = optim.SGD([X_pgd], lr=1e-3)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            loss = nn.CrossEntropyLoss()(model(X_pgd), y)\n",
    "        loss.backward()\n",
    "        eta = step_size * X_pgd.grad.data.sign()\n",
    "        X_pgd = Variable(X_pgd.data + eta, requires_grad=True)\n",
    "        eta = torch.clamp(X_pgd.data - X.data, -epsilon, epsilon)\n",
    "        X_pgd = Variable(X.data + eta, requires_grad=True)\n",
    "        X_pgd = Variable(torch.clamp(X_pgd, 0, 1.0), requires_grad=True)\n",
    "    err_pgd = (model(X_pgd).data.max(1)[1] != y.data).float().sum()\n",
    "    return err, err_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f33a6e-285d-4de4-b870-83df49a3f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_adv_test_whitebox(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    robust_err_total = 0\n",
    "    natural_err_total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # pgd attack\n",
    "        X, y = Variable(data, requires_grad=True), Variable(target)\n",
    "        err_natural, err_robust = _pgd_whitebox(model, X, y)\n",
    "        robust_err_total += err_robust\n",
    "        natural_err_total += err_natural\n",
    "        \n",
    "    natural_acc = 1 - natural_err_total / len(test_loader.dataset)\n",
    "    robust_acc = 1- robust_err_total / len(test_loader.dataset)\n",
    "    robust_drop = natural_acc - robust_acc\n",
    "    attack_success_rate = 1 - robust_acc \n",
    "    \n",
    "    print(f'PGD natural_acc: {natural_acc:.4f}, robust_acc: {robust_acc:.4f}, robust_drop: {robust_drop:4f}, attack_success_rate: {attack_success_rate:4f}')\n",
    "    return natural_acc, robust_acc, robust_drop, attack_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce3ad94-b375-4793-ab78-cad54989ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"decrease the learning rate\"\"\"\n",
    "    lr = args.lr\n",
    "    if epoch >= 75:\n",
    "        lr = args.lr * 0.1\n",
    "    if epoch >= 90:\n",
    "        lr = args.lr * 0.01\n",
    "    if epoch >= 100:\n",
    "        lr = args.lr * 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c1140d9-1360-4337-9c6e-f11c5b3ea1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a654d3-7f22-4dcb-a155-8f0b736ec47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.313191 \tLambda Mean: 1.08 \tLambda Min: 0.96 \tLambda Max: 1.21\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.869186 \tLambda Mean: 0.99 \tLambda Min: 0.02 \tLambda Max: 1.97\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.785190 \tLambda Mean: 0.82 \tLambda Min: 0.06 \tLambda Max: 1.65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Max Robust Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(hist[\u001b[33m'\u001b[39m\u001b[33mrobust_acc\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m start_time = time.time()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Entrenamiento adversarial\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m================================================================\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Evaluación\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(args, model, device, train_loader, optimizer, epoch)\u001b[39m\n\u001b[32m      5\u001b[39m model.train()\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     data, target = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, target.to(device)\n\u001b[32m      9\u001b[39m     optimizer.zero_grad()\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# calculate robust loss\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if args.model.lower() == \"resnet\":\n",
    "        model = ResNet18()\n",
    "    elif args.model.lower() == \"vgg\":\n",
    "        model = vgg16()\n",
    "    else:\n",
    "        raise ValueError(\"Modelo no reconocido: usa --model resnet o --model vgg\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    # Historial\n",
    "    history = {'natural_acc': [], 'robust_acc': [], 'robust_drop': [], 'attack_succes_rate': []}\n",
    "    results = {}\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # Entrenamiento adversarial\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "        print('================================================================')\n",
    "        \n",
    "        # Evaluación\n",
    "        natural_acc, robust_acc, robust_drop, attack_succes_rate = eval_adv_test_whitebox(\n",
    "            model, device, test_loader\n",
    "        )\n",
    "\n",
    "        print('using time:', time.time() - start_time)\n",
    "        print('================================================================')\n",
    "        \n",
    "        # Guardar historial\n",
    "        history['natural_acc'].append(natural_acc)\n",
    "        history['robust_acc'].append(robust_acc)\n",
    "        history['robust_drop'].append(robust_drop)\n",
    "        history['attack_succes_rate'].append(attack_succes_rate)\n",
    "\n",
    "        results[f'history{epoch}'] = history.copy()\n",
    "\n",
    "        # Guardar checkpoints\n",
    "        if epoch % args.save_freq == 0:\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(model_dir, f'model-nn-epoch{epoch}.pt'))\n",
    "            torch.save(optimizer.state_dict(),\n",
    "                       os.path.join(model_dir, f'opt-nn-checkpoint_epoch{epoch}.tar'))\n",
    "    \n",
    "    print('================================================================')\n",
    "    print(\"\\nResumen de Resultados por historial:\")\n",
    "    for ep, hist in results.items():\n",
    "        print(f\"{ep}: Max Robust Acc: {max(hist['robust_acc']):.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
