{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44c9b307-bea3-49db-b5f3-6505e0a13c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchattacks\n",
    "import autoattack\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from models.resnet import *\n",
    "from models.vgg import *\n",
    "from autoattack import AutoAttack  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13cec3e6-3c13-48a9-a577-97e4d1102dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST PGD Attack Evaluation')\n",
    "parser.add_argument('--test-batch-size', type=int, default=200, metavar='N',\n",
    "                    help='input batch size for testing (default: 200)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--epsilon', default=0.3,\n",
    "                    help='perturbation')\n",
    "parser.add_argument('--num-steps', default=40,\n",
    "                    help='perturb number of steps')\n",
    "parser.add_argument('--step-size', default=0.01,\n",
    "                    help='perturb step size')\n",
    "parser.add_argument('--random',\n",
    "                    default=True,\n",
    "                    help='random initialization for PGD')\n",
    "parser.add_argument('--white-box-attack', default=True,\n",
    "                    help='whether perform white-box attack')\n",
    "parser.add_argument('--model', type=str, default='vgg', choices=['resnet', 'vgg'],\n",
    "                    help='Modelo a usar: resnet o vgg')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a25a705b-ebd4-476f-9127-904fa6eb3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustes\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8905a49b-08ac-4c6c-b18d-7a3c609d7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el cargador de datos\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),])\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d0eb7b8-5188-4d90-90e5-f486e211dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path (model):\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Attack Evaluation')\n",
    "    if (model['dataset'] == 'mnist'):\n",
    "        if (model['estrategia'] == 'trades-mnist-vgg16'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-trades-mnist-vgg16/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia']== 'trades-mnist-resnet'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-trades-mnist-resnet18/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'mart-mnist-vgg16'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-mnist-mart-vgg16/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'mart-mnist-resnet'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-mnist-mart-resnet18/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'faal-mnist-vgg16'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-mnist-faal-vgg16/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'faal-mnist-resnet'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-mnist-faal-resnet18/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'Dtrades-mnist-resnet'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-D-trades-mnist-resnet18/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'Dtrades-mnist-vgg16'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-D-trades-mnist-vgg16/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'Dtrades-mnist-resnet-a1-b1'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-D-trades-mnist-resnet18-alpha1-beta1/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'Dtrades-mnist-vgg16-a1-b1'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='./model-D-trades-mnist-vgg16-alpha1-beta1/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'standar-mnist-resnet18'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='model-standard-mnist-resnet18/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "        elif(model['estrategia'] == 'standar-mnist-vgg16'):\n",
    "            parser.add_argument('--model-path',\n",
    "                        default='model-standard-mnist-vgg16/model-nn-epoch50.pt',\n",
    "                        help='model for white-box attack evaluation')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "808bd81d-d114-4887-94da-258403851fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pgd_whitebox(model,\n",
    "                  X,\n",
    "                  y,\n",
    "                  epsilon=args.epsilon,\n",
    "                  num_steps=20,\n",
    "                  step_size=0.003):\n",
    "    out = model(X)\n",
    "    err = (out.data.max(1)[1] != y.data).float().sum()\n",
    "    X_pgd = Variable(X.data, requires_grad=True)\n",
    "\n",
    "    random_noise = torch.FloatTensor(*X_pgd.shape).uniform_(-epsilon, epsilon).to(device)\n",
    "    X_pgd = Variable(X_pgd.data + random_noise, requires_grad=True)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        opt = optim.SGD([X_pgd], lr=1e-3)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            loss = nn.CrossEntropyLoss()(model(X_pgd), y)\n",
    "        loss.backward()\n",
    "        eta = step_size * X_pgd.grad.data.sign()\n",
    "        X_pgd = Variable(X_pgd.data + eta, requires_grad=True)\n",
    "        eta = torch.clamp(X_pgd.data - X.data, -epsilon, epsilon)\n",
    "        X_pgd = Variable(X.data + eta, requires_grad=True)\n",
    "        X_pgd = Variable(torch.clamp(X_pgd, 0, 1.0), requires_grad=True)\n",
    "    err_pgd = (model(X_pgd).data.max(1)[1] != y.data).float().sum()\n",
    "    return err, err_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c9a8270-c485-4199-83f0-94e20acdba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_adv_test_whitebox(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    robust_err_total = 0\n",
    "    natural_err_total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # pgd attack\n",
    "        X, y = Variable(data, requires_grad=True), Variable(target)\n",
    "        err_natural, err_robust = _pgd_whitebox(model, X, y)\n",
    "        robust_err_total += err_robust\n",
    "        natural_err_total += err_natural\n",
    "        \n",
    "    natural_acc = 1 - natural_err_total / len(test_loader.dataset)\n",
    "    robust_acc = 1- robust_err_total / len(test_loader.dataset)\n",
    "    robust_drop = natural_acc - robust_acc\n",
    "    attack_success_rate = 1 - robust_acc\n",
    "    \n",
    "    print(f'PGD natural_acc: {natural_acc:.4f}, robust_acc: {robust_acc:.4f}, robust_drop: {robust_drop:4f}, attack_success_rate: {attack_success_rate:4f}')\n",
    "    return natural_acc, robust_acc, robust_drop, attack_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c46c3561-83fd-4081-9c8d-8aabd1aecd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fgsm_whitebox(model, X, y, epsilon):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(X)\n",
    "    err_natural = (out.data.max(1)[1] != y.data).float().sum()\n",
    "\n",
    "    X_adv = X.clone().detach().requires_grad_(True)\n",
    "\n",
    "    outputs = model(X_adv)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, y)\n",
    "\n",
    "    model.zero_grad()\n",
    "    if X_adv.grad is not None:\n",
    "        X_adv.grad.zero_()\n",
    "    loss.backward()\n",
    "\n",
    "    eta = epsilon * X_adv.grad.data.sign()\n",
    "    X_adv = X_adv.data + eta\n",
    "    X_adv = torch.clamp(X_adv, 0.0, 1.0)          \n",
    "    X_adv = X_adv.detach()                        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_adv = model(X_adv)\n",
    "    err_adv = (out_adv.data.max(1)[1] != y.data).float().sum()\n",
    "\n",
    "    return err_natural, err_adv, X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61e6cc7f-a63a-42ad-8fee-d57ecd627332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_adv_test_fgsm(model, device, test_loader, epsilon=0.03):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    natural_err_total = 0.0\n",
    "    robust_err_total = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        batch_size = data.size(0)\n",
    "        total += batch_size\n",
    "\n",
    "        err_nat, err_adv, _ = _fgsm_whitebox(model, data, target, epsilon)\n",
    "        natural_err_total += err_nat\n",
    "        robust_err_total += err_adv\n",
    "\n",
    "    natural_acc = 1.0 - (natural_err_total / total)\n",
    "    robust_acc  = 1.0 - (robust_err_total / total)\n",
    "    robust_drop = natural_acc - robust_acc\n",
    "    attack_success_rate = 1 - robust_acc\n",
    "    \n",
    "    print(f'FGSM natural_acc: {natural_acc:.4f}, robust_acc: {robust_acc:.4f}, robust_drop: {robust_drop:4f}, attack_success_rate: {attack_success_rate:4f}')\n",
    "    return natural_acc, robust_acc, robust_drop, attack_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28948910-f22d-49eb-bcb5-0d5f16333932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_adv_test_autoattack(model, device, test_loader, \n",
    "                             norm='Linf', \n",
    "                             eps=8/255, \n",
    "                             max_samples=1000):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    total_samples = 0\n",
    "    for x, y in test_loader:\n",
    "        x_test.append(x)\n",
    "        y_test.append(y)\n",
    "        total_samples += x.size(0)\n",
    "        if total_samples >= max_samples:\n",
    "            break\n",
    "            \n",
    "    x_test = torch.cat(x_test, dim=0)[:max_samples].to(device)\n",
    "    y_test = torch.cat(y_test, dim=0)[:max_samples].to(device)\n",
    "    total = x_test.size(0)\n",
    "\n",
    "    print(f\"Iniciando evaluación con AutoAttack ({total} muestras, Norma: {norm}, Epsilon: {eps:.4f}).\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    adversary = autoattack.AutoAttack(\n",
    "        model, \n",
    "        norm=norm, \n",
    "        eps=eps, \n",
    "        log_path=None,\n",
    "        version='standard', \n",
    "        device=device,\n",
    "        seed=0\n",
    "    )\n",
    "\n",
    "    x_adv = adversary.run_standard_evaluation(x_test, y_test)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_nat = model(x_test)\n",
    "        natural_err_total = (out_nat.max(1)[1] != y_test).float().sum().item()\n",
    "        \n",
    "        out_adv = model(x_adv)\n",
    "        robust_err_total = (out_adv.max(1)[1] != y_test).float().sum().item()\n",
    "        \n",
    "    natural_acc = 1.0 - (natural_err_total / total)\n",
    "    robust_acc  = 1.0 - (robust_err_total / total)\n",
    "    robust_drop = natural_acc - robust_acc\n",
    "    attack_success_rate = 1.0 - robust_acc\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print(f'Métricas de Robustez con AutoAttack {norm}:')\n",
    "    print(f'   -> Precisión Natural:       {natural_acc:.4f}')\n",
    "    print(f'   -> Precisión Robusta (AA):  {robust_acc:.4f}')\n",
    "    print(f'   -> Caída de Robustez:       {robust_drop:.4f}')\n",
    "    print(f'   -> Tasa de Éxito del Ataque: {attack_success_rate:.4f}')\n",
    "    print('----------------------------------------------------------------')\n",
    "    \n",
    "    return natural_acc, robust_acc, robust_drop, attack_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6710c2cc-f5be-457f-a732-372c7df7cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './attacks-mnist'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "471ba435-3865-4b38-9925-ff59c627206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_name(path):\n",
    "    return path.replace('/', '_').replace('\\\\', '_').replace(':', '_').replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271dc1eb-0e8c-458c-9553-8c5ce53b68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white-box attacks\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if args.white_box_attack:\n",
    "        \n",
    "        print('white-box attacks')\n",
    "        if args.model.lower() == \"resnet\":\n",
    "            model = ResNet18()\n",
    "            model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        elif args.model.lower() == \"vgg\":\n",
    "            model = vgg16(in_channels=1)\n",
    "        else:\n",
    "            raise ValueError(\"Modelo no reconocido: usa --model resnet o --model vgg\")\n",
    "            \n",
    "        validation_results = []\n",
    "        model = model.to(device)\n",
    "        estrategy = {'dataset': 'mnist',\n",
    "                     'estrategia': 'standar-mnist-vgg16'}\n",
    "        \n",
    "        args_path = path(estrategy)\n",
    "        \n",
    "        model.load_state_dict(torch.load(args_path.model_path))\n",
    "        \n",
    "        print('================================================================')\n",
    "        natural_acc_pgd,robust_acc_pgd, robust_drop_pgd, attack_success_pgd = eval_adv_test_whitebox(model, device, test_loader) #PGD20\n",
    "        natural_acc_fgsm, robust_acc_fgsm, robust_drop_fgsm, attack_success_fgsm  = eval_adv_test_fgsm(model, device, test_loader) #FGSM\n",
    "        natural_acc_auto, robust_acc_auto, robust_drop_auto, attack_success_auto = eval_adv_test_autoattack(model, device, test_loader) #AutoAttack\n",
    "\n",
    "        validation_results.append({\n",
    "            \"Model\": {args_path.model_path},\n",
    "            \"pgd_natural\": natural_acc_pgd,\n",
    "            \"pgd_robust\": robust_acc_pgd,\n",
    "            \"pgd_drop\": robust_drop_pgd,\n",
    "            \"attack_succes_pgd\": attack_success_pgd,\n",
    "            \"fgsm_natural\": natural_acc_fgsm,\n",
    "            \"fgsm_robust\": robust_acc_fgsm,\n",
    "            \"fgsm_drop\": robust_drop_fgsm,\n",
    "            \"attack_success_fgsm\": attack_success_fgsm,\n",
    "            \"auto_natural\": natural_acc_auto,\n",
    "            \"auto_robust\": robust_acc_auto,\n",
    "            \"auto_drop\": robust_drop_auto,\n",
    "            \"attack_success_auto\": attack_success_auto\n",
    "        })\n",
    "        results_file = os.path.join(log_dir, f\"evaluate_{safe_name(args_path.model_path)}.csv\")\n",
    "        \n",
    "        df_results = pd.DataFrame(validation_results)\n",
    "        df_results.to_csv(results_file, index=False) \n",
    "        print(df_results)\n",
    "        print('================================================================')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
